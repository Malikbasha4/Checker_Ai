import streamlit as st

from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM

import nltk

from nltk.corpus import stopwords

from nltk.tokenize import word_tokenize

from collections import Counter

import spacy

from sklearn.feature_extraction.text import TfidfVectorizer

from sklearn.decomposition import NMF # Non-negative Matrix Factorization for topic modeling

from textstat import flesch_kincaid_grade, flesch_reading_ease # For readability

from langdetect import detect, DetectorFactory # For language detection

from wordcloud import WordCloud # For word cloud visualization

import matplotlib.pyplot as plt

import io # For handling byte streams for downloads



# --- Set random seed for reproducibility of langdetect ---

# This makes langdetect results consistent across runs

DetectorFactory.seed = 0



# --- NLTK Downloads (Run unconditionally at the start) ---

# This ensures the necessary NLTK data is downloaded before any other NLTK operations.

# Removed st.info here as the downloads are quiet and don't need to show on UI

nltk.download('stopwords', quiet=True) # Use quiet=True to suppress verbose output if not needed

nltk.download('punkt', quiet=True)

nltk.download('punkt_tab', quiet=True) # Added download for 'punkt_tab'



# --- Load Models (Cached for performance) ---

# This decorator ensures the function runs only once and caches the result

@st.cache_resource

def load_summarizer_model():

Â  Â  """Loads the pre-trained summarization model."""

Â  Â  return pipeline("summarization", model="sshleifer/distilbart-cnn-12-6")



@st.cache_resource

def load_sentiment_model():

Â  Â  """Loads the pre-trained sentiment analysis model."""

Â  Â  return pipeline("sentiment-analysis")



@st.cache_resource

def load_spacy_model():

Â  Â  """Loads the spaCy English model for NER."""

Â  Â  return spacy.load("en_core_web_sm")



@st.cache_resource

def load_text_generation_model():

Â  Â  """Loads the pre-trained text generation model."""

Â  Â  return pipeline("text-generation", model="gpt2")



@st.cache_resource

def load_translation_models():

Â  Â  """Loads pre-trained translation models for multiple languages."""

Â  Â  # Removed st.info and st.write calls from here to keep the UI clean during loading

Â  Â  translation_pipelines = {}

Â  Â 

Â  Â  # Define language pairs and their corresponding Hugging Face model names

Â  Â  # Using Helsinki-NLP/opus-mt for various language pairs

Â  Â  # Removed Hindi, Japanese, Korean, Tamil, and Bengali models due to loading issues or user request.

Â  Â  language_models = {

Â  Â  Â  Â  "French": "Helsinki-NLP/opus-mt-en-fr",

Â  Â  Â  Â  "Chinese": "Helsinki-NLP/opus-mt-en-zh",

Â  Â  Â  Â  "German": "Helsinki-NLP/opus-mt-en-de",

Â  Â  Â  Â  "Arabic": "Helsinki-NLP/opus-mt-en-ar",

Â  Â  Â  Â  "Spanish": "Helsinki-NLP/opus-mt-en-es",

Â  Â  Â  Â  "Portuguese": "Helsinki-NLP/opus-mt-en-pt", # Re-added Portuguese

Â  Â  Â  Â  "Russian": "Helsinki-NLP/opus-mt-en-ru",

Â  Â  }



Â  Â  for lang_name, model_name in language_models.items():

Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  tokenizer = AutoTokenizer.from_pretrained(model_name)

Â  Â  Â  Â  Â  Â  model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

Â  Â  Â  Â  Â  Â  translation_pipelines[lang_name] = pipeline("translation", model=model, tokenizer=tokenizer)

Â  Â  Â  Â  Â  Â  # st.write(f"Loaded English to {lang_name} model.") # Removed this line

Â  Â  Â  Â  except Exception as e:

Â  Â  Â  Â  Â  Â  # st.error(f"Could not load translation model for {lang_name} ({model_name}): {e}") # Removed this line

Â  Â  Â  Â  Â  Â  # st.warning(f"Please ensure 'sentencepiece' is installed and check model availability for {lang_name}.") # Removed this line

Â  Â  Â  Â  Â  Â  translation_pipelines[lang_name] = None # Mark as None if loading fails

Â  Â  Â  Â  Â  Â 

Â  Â  return translation_pipelines



# Initialize models

with st.spinner("Initializing models... This might take a moment."):

Â  Â  summarizer = load_summarizer_model()

Â  Â  sentiment_analyzer = load_sentiment_model()

Â  Â  nlp_spacy = load_spacy_model()

Â  Â  text_generator = load_text_generation_model()

Â  Â  translators = load_translation_models() # Now loads multiple translators

# Removed st.success("Models initialized!") to keep the UI cleaner after loading

# The spinner disappearing is enough indication of completion.



# --- Helper Functions ---



def extract_keywords(text, num_keywords=10):

Â  Â  """

Â  Â  Extracts keywords using NLTK tokenization and frequency counting.

Â  Â  Filters out stopwords and punctuation.

Â  Â  """

Â  Â  words = word_tokenize(text.lower())

Â  Â  stop_words = set(stopwords.words('english'))

Â  Â  # Filter out stopwords and non-alphabetic tokens

Â  Â  filtered_words = [word for word in words if word.isalpha() and word not in stop_words]

Â  Â  word_counts = Counter(filtered_words)

Â  Â  return [word for word, count in word_counts.most_common(num_keywords)]



def perform_ner(text):

Â  Â  """

Â  Â  Performs Named Entity Recognition using spaCy.

Â  Â  Returns a list of dictionaries with entity text, label, and explanation.

Â  Â  """

Â  Â  doc = nlp_spacy(text)

Â  Â  entities = []

Â  Â  for ent in doc.ents:

Â  Â  Â  Â  entities.append({

Â  Â  Â  Â  Â  Â  "text": ent.text,

Â  Â  Â  Â  Â  Â  "label": ent.label_,

Â  Â  Â  Â  Â  Â  "explanation": spacy.explain(ent.label_)

Â  Â  Â  Â  })

Â  Â  return entities



def perform_topic_modeling(text, num_topics=3, num_words=5):

Â  Â  """

Â  Â  Performs topic modeling using NMF.

Â  Â  Returns a list of dominant topics with their keywords.

Â  Â  """

Â  Â  if not text.strip():

Â  Â  Â  Â  return []



Â  Â  # Ensure text is long enough for meaningful topic modeling

Â  Â  if len(text.split()) < 50: # Arbitrary threshold for meaningful topic modeling

Â  Â  Â  Â  return []



Â  Â  vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')

Â  Â  try:

Â  Â  Â  Â  dtm = vectorizer.fit_transform([text])

Â  Â  except ValueError: # Handle cases where text is too short after stopword removal

Â  Â  Â  Â  return []



Â  Â  # Check if dtm has enough features for NMF

Â  Â  if dtm.shape[1] < num_topics:

Â  Â  Â  Â  return []



Â  Â  nmf_model = NMF(n_components=num_topics, random_state=1, alpha_W=0.01, alpha_H=0.01)

Â  Â  nmf_model.fit(dtm)



Â  Â  feature_names = vectorizer.get_feature_names_out()

Â  Â  topics = []

Â  Â  for topic_idx, topic in enumerate(nmf_model.components_):

Â  Â  Â  Â  top_words = [feature_names[i] for i in topic.argsort()[:-num_words - 1:-1]]

Â  Â  Â  Â  topics.append(f"Topic {topic_idx + 1}: {', '.join(top_words)}")

Â  Â  return topics



def generate_wordcloud(text, keywords):

Â  Â  """Generates a word cloud image from the text, focusing on keywords."""

Â  Â  if not keywords:

Â  Â  Â  Â  return None



Â  Â  # Create a frequency dictionary from keywords to emphasize them

Â  Â  word_freq = Counter(keywords)

Â  Â  # Add other words from the text but with lower weight

Â  Â  words = word_tokenize(text.lower())

Â  Â  stop_words = set(stopwords.words('english'))

Â  Â  filtered_words = [word for word in words if word.isalpha() and word not in stop_words]

Â  Â  for word in filtered_words:

Â  Â  Â  Â  if word not in word_freq:

Â  Â  Â  Â  Â  Â  word_freq[word] = 1 # Give a base frequency if not a top keyword



Â  Â  wordcloud = WordCloud(width=800, height=400, background_color='white',

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  max_words=50, collocations=False).generate_from_frequencies(word_freq)



Â  Â  fig, ax = plt.subplots(figsize=(10, 5))

Â  Â  ax.imshow(wordcloud, interpolation='bilinear')

Â  Â  ax.axis('off')

Â  Â  return fig



# --- Streamlit UI ---



st.set_page_config(layout="wide", page_title="Advanced Intelligent Text Analysis Workbench")



st.title("ðŸ§  Advanced Intelligent Text Analysis Workbench")

st.markdown("""

Â  Â  This powerful app leverages advanced Machine Learning and Deep Learning models

Â  Â  to provide comprehensive insights into your text.

Â  Â  It offers summarization, keyword extraction, sentiment analysis, named entity recognition,

Â  Â  text generation, topic modeling, readability scores, language detection, and translation.

""")



# Sidebar for additional features and settings

st.sidebar.header("âš™ï¸ Settings & Advanced Features")

analysis_options = st.sidebar.multiselect(

Â  Â  "Select Analysis Features:",

Â  Â  ["Summarization", "Keyword Extraction", "Sentiment Analysis", "Named Entity Recognition",

Â  Â  Â "Text Generation", "Topic Modeling", "Readability Score", "Language Detection", "Translation", "Word Cloud"],

Â  Â  default=["Summarization", "Keyword Extraction", "Sentiment Analysis", "Named Entity Recognition"]

)



# Text Input Area

st.header("1. Enter Your Text")

input_text = st.text_area(

Â  Â  "Paste your text here:",

Â  Â  height=300,

Â  Â  placeholder="Type or paste any text you want to analyze (e.g., an article, a speech, a review)...",

Â  Â  key="main_input_text" # Added key for better state management

)



# Clear Text Button

if st.button("Clear Text", help="Clears the input text area"):

Â  Â  st.session_state.main_input_text = "" # Clear the text area

Â  Â  st.experimental_rerun() # Rerun to reflect the cleared text



if input_text:

Â  Â  st.markdown("---")

Â  Â  st.header("2. Analysis Results")



Â  Â  # --- Summarization ---

Â  Â  if "Summarization" in analysis_options:

Â  Â  Â  Â  with st.expander("ðŸ“ Text Summary", expanded=True): # Removed (Deep Learning)

Â  Â  Â  Â  Â  Â  with st.spinner("Generating summary..."):

Â  Â  Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Min/Max length for summarization, adjusted dynamically

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  words_in_text = len(input_text.split())

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  min_len = min(50, words_in_text // 4)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  max_len = min(200, words_in_text // 2)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if words_in_text < 50: # Summarization models struggle with very short texts

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning("Text is too short for effective summarization. Minimum recommended words: 50.")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  summary = "Not enough text to generate a meaningful summary."

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  summary = summarizer(input_text, max_length=max_len, min_length=min_len, do_sample=False)[0]['summary_text']

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success("Summary Generated:")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.write(summary)

Â  Â  Â  Â  Â  Â  Â  Â  except Exception as e:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"Error generating summary: {e}")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning("Summarization might fail for very short texts or due to model limitations.")



Â  Â  # --- Keyword Extraction ---

Â  Â  if "Keyword Extraction" in analysis_options:

Â  Â  Â  Â  with st.expander("ðŸ”‘ Keywords/Key Phrases", expanded=True): # Removed (NLP)

Â  Â  Â  Â  Â  Â  with st.spinner("Extracting keywords..."):

Â  Â  Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  keywords = extract_keywords(input_text)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if keywords:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success("Extracted Keywords:")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(f"**`{', '.join(keywords)}`**")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.info("No significant keywords found or text is too short.")

Â  Â  Â  Â  Â  Â  Â  Â  except Exception as e:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"Error extracting keywords: {e}")



Â  Â  # --- Word Cloud ---

Â  Â  if "Word Cloud" in analysis_options and "Keyword Extraction" in analysis_options:

Â  Â  Â  Â  with st.expander("â˜ï¸ Word Cloud Visualization", expanded=True):

Â  Â  Â  Â  Â  Â  with st.spinner("Generating word cloud..."):

Â  Â  Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  keywords_for_cloud = extract_keywords(input_text, num_keywords=50) # Get more keywords for cloud

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  wordcloud_fig = generate_wordcloud(input_text, keywords_for_cloud)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if wordcloud_fig:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.pyplot(wordcloud_fig)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.info("Not enough keywords to generate a meaningful word cloud.")

Â  Â  Â  Â  Â  Â  Â  Â  except Exception as e:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"Error generating word cloud: {e}")



Â  Â  # --- Sentiment Analysis ---

Â  Â  if "Sentiment Analysis" in analysis_options:

Â  Â  Â  Â  with st.expander("ðŸ˜Š Sentiment Analysis", expanded=True): # Removed (ML/NLP)

Â  Â  Â  Â  Â  Â  with st.spinner("Analyzing sentiment..."):

Â  Â  Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Added truncation and max_length to handle long inputs

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  sentiment_result = sentiment_analyzer(input_text, truncation=True, max_length=512)[0]

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  label = sentiment_result['label']

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  score = sentiment_result['score']

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success("Sentiment Detected:")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(f"**Label:** `{label}` (Confidence: `{score:.2f}`)")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if label == "POSITIVE":

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.balloons()

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  elif label == "NEGATIVE":

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.snow()

Â  Â  Â  Â  Â  Â  Â  Â  except Exception as e:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"Error analyzing sentiment: {e}")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning("Sentiment analysis might be less accurate for very short or ambiguous texts.")



Â  Â  # --- Named Entity Recognition ---

Â  Â  if "Named Entity Recognition" in analysis_options:

Â  Â  Â  Â  with st.expander("ðŸ‘¤ðŸ¢ðŸ“ Named Entity Recognition", expanded=True): # Removed (Advanced NLP)

Â  Â  Â  Â  Â  Â  with st.spinner("Identifying entities..."):

Â  Â  Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  entities = perform_ner(input_text)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if entities:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success("Identified Entities:")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  entity_data = [{"Entity": ent["text"], "Type": ent["label"], "Description": ent["explanation"]} for ent in entities]

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.table(entity_data)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.info("No named entities found in the text.")

Â  Â  Â  Â  Â  Â  Â  Â  except Exception as e:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"Error performing NER: {e}")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning("NER might not identify all entities accurately, especially in informal text.")



Â  Â  # --- Text Generation ---

Â  Â  if "Text Generation" in analysis_options:

Â  Â  Â  Â  with st.expander("âœï¸ Text Generation/Completion", expanded=False): # Removed (Deep Learning)

Â  Â  Â  Â  Â  Â  st.markdown("Enter a prompt and the model will try to complete it.")

Â  Â  Â  Â  Â  Â  generation_prompt = st.text_area("Enter your prompt for text generation:", value=input_text[:100], height=100, key="gen_prompt")

Â  Â  Â  Â  Â  Â  max_gen_length = st.slider("Max generated text length:", min_value=50, max_value=500, value=200, step=10)

Â  Â  Â  Â  Â  Â  if st.button("Generate Text"):

Â  Â  Â  Â  Â  Â  Â  Â  with st.spinner("Generating text..."):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Modified text generation parameters for more diverse output

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  generated_text = text_generator(

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  generation_prompt,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  max_length=max_gen_length,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  num_return_sequences=1,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  do_sample=True, Â # Enable sampling for more varied output

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  top_k=50, Â  Â  Â  Â # Consider only the top 50 most likely words

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  top_p=0.95, Â  Â  Â # Sample from the smallest set of words whose cumulative probability exceeds 0.95

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  temperature=0.7, # Control randomness (lower = more predictable, higher = more creative)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  no_repeat_ngram_size=2 # Prevent repeating 2-word sequences

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )[0]['generated_text']

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success("Generated Text:")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.write(generated_text)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  except Exception as e:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"Error generating text: {e}")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning("Text generation might produce nonsensical or repetitive results.")



Â  Â  # --- Topic Modeling ---

Â  Â  if "Topic Modeling" in analysis_options:

Â  Â  Â  Â  with st.expander("ðŸ“Š Topic Modeling", expanded=False): # Removed (Machine Learning)

Â  Â  Â  Â  Â  Â  num_topics = st.slider("Number of topics to find:", min_value=1, max_value=10, value=3)

Â  Â  Â  Â  Â  Â  num_topic_words = st.slider("Number of keywords per topic:", min_value=3, max_value=10, value=5)

Â  Â  Â  Â  Â  Â  with st.spinner("Performing topic modeling..."):

Â  Â  Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  topics = perform_topic_modeling(input_text, num_topics, num_topic_words)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if topics:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success("Identified Topics:")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for topic in topics:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.write(f"- {topic}")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.info("Not enough text or too few unique words to perform meaningful topic modeling.")

Â  Â  Â  Â  Â  Â  Â  Â  except Exception as e:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"Error performing topic modeling: {e}")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning("Topic modeling works best on longer, coherent texts.")



Â  Â  # --- Readability Score ---

Â  Â  if "Readability Score" in analysis_options:

Â  Â  Â  Â  with st.expander("ðŸ“– Readability Score", expanded=False): # Removed (NLP)

Â  Â  Â  Â  Â  Â  with st.spinner("Calculating readability..."):

Â  Â  Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  fk_grade = flesch_kincaid_grade(input_text)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  flesch_ease = flesch_reading_ease(input_text)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success("Readability Scores:")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(f"**Flesch-Kincaid Grade Level:** `{fk_grade:.2f}` (Approximate grade level needed to understand the text)")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(f"**Flesch Reading Ease Score:** `{flesch_ease:.2f}` (Higher score means easier to read)")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Simplified explanation for a 10-year-old

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.info("""

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Think of these scores like a report card for your text!

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  * **Flesch-Kincaid Grade Level:** This number tells you what school grade level (like 5th grade or 10th grade) someone would generally need to be in to easily understand your text.

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  * **Flesch Reading Ease Score:** This number tells you how "easy" your text is to read. Higher numbers mean it's super easy (like a storybook!), and lower numbers mean it's a bit trickier (like a science book).

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  These scores are just a guess, but they help you see if your writing is easy for others to understand!

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  """)

Â  Â  Â  Â  Â  Â  Â  Â  except Exception as e:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"Error calculating readability: {e}")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning("Readability scores require sufficient text length to be accurate.")



Â  Â  # --- Language Detection ---

Â  Â  if "Language Detection" in analysis_options:

Â  Â  Â  Â  with st.expander("ðŸŒ Language Detection", expanded=False): # Removed (NLP)

Â  Â  Â  Â  Â  Â  with st.spinner("Detecting language..."):

Â  Â  Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  detected_lang = detect(input_text)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success("Language Detected:")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(f"**Detected Language:** `{detected_lang.upper()}`")

Â  Â  Â  Â  Â  Â  Â  Â  except Exception as e:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"Error detecting language: {e}")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning("Language detection might fail for very short texts or mixed languages.")



Â  Â  # --- Text Translation ---

Â  Â  if "Translation" in analysis_options:

Â  Â  Â  Â  with st.expander("ðŸŒ Text Translation", expanded=False): # Removed (Deep Learning)

Â  Â  Â  Â  Â  Â  st.markdown("Translate your text from English to another language.")

Â  Â  Â  Â  Â  Â 

Â  Â  Â  Â  Â  Â  # Get available languages from the loaded models

Â  Â  Â  Â  Â  Â  available_languages = sorted([lang for lang, pipe in translators.items() if pipe is not None])

Â  Â  Â  Â  Â  Â  if not available_languages:

Â  Â  Â  Â  Â  Â  Â  Â  st.warning("No translation models were loaded successfully. Translation feature is unavailable.")

Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  target_lang = st.selectbox("Translate to:", available_languages, key="target_lang")

Â  Â  Â  Â  Â  Â  Â  Â 

Â  Â  Â  Â  Â  Â  Â  Â  if st.button("Translate Text"):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if translators[target_lang] is not None:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with st.spinner(f"Translating to {target_lang}..."):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Use the specific translator pipeline for the selected language

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Added truncation=True to handle long inputs

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  translation_result = translators[target_lang](

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  input_text,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  max_length=512,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  truncation=True,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  do_sample=True, # Enable sampling for more varied output

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  top_k=50, Â  Â  Â  # Consider only the top 50 most likely words

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  top_p=0.95, Â  Â  # Sample from the smallest set of words whose cumulative probability exceeds 0.95

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  temperature=0.7,# Control randomness (lower = more predictable, higher = more creative)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  no_repeat_ngram_size=2 # Prevent repeating 2-word sequences

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )[0]['translation_text']

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success(f"Translated Text (to {target_lang}):")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.write(translation_result)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  except Exception as e:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"Error translating text to {target_lang}: {e}")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning("Translation might be limited by model's language pair and text length.")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"Translation model for {target_lang} was not loaded successfully. Cannot translate.")





Â  Â  # --- Download Results ---

Â  Â  st.markdown("---")

Â  Â  st.header("3. Download Results")

Â  Â  if input_text:

Â  Â  Â  Â  # Initialize variables that might not be set if their features are not selected

Â  Â  Â  Â  summary = "N/A"

Â  Â  Â  Â  keywords = []

Â  Â  Â  Â  label = "N/A"

Â  Â  Â  Â  score = "N/A"

Â  Â  Â  Â  entity_data = "N/A"

Â  Â  Â  Â  generated_text = "N/A"

Â  Â  Â  Â  topics = "N/A"

Â  Â  Â  Â  fk_grade = "N/A"

Â  Â  Â  Â  flesch_ease = "N/A"

Â  Â  Â  Â  detected_lang = "N/A"

Â  Â  Â  Â  translation_result = "N/A"



Â  Â  Â  Â  # Re-assign if features were selected and results were generated

Â  Â  Â  Â  if "Summarization" in analysis_options and 'summary' in locals():

Â  Â  Â  Â  Â  Â  summary = locals()['summary']

Â  Â  Â  Â  if "Keyword Extraction" in analysis_options and 'keywords' in locals():

Â  Â  Â  Â  Â  Â  keywords = locals()['keywords']

Â  Â  Â  Â  if "Sentiment Analysis" in analysis_options and 'label' in locals():

Â  Â  Â  Â  Â  Â  label = locals()['label']

Â  Â  Â  Â  Â  Â  score = locals()['score']

Â  Â  Â  Â  if "Named Entity Recognition" in analysis_options and 'entity_data' in locals():

Â  Â  Â  Â  Â  Â  entity_data = locals()['entity_data']

Â  Â  Â  Â  if "Text Generation" in analysis_options and 'generated_text' in locals():

Â  Â  Â  Â  Â  Â  generated_text = locals()['generated_text']

Â  Â  Â  Â  if "Topic Modeling" in analysis_options and 'topics' in locals():

Â  Â  Â  Â  Â  Â  topics = locals()['topics']

Â  Â  Â  Â  if "Readability Score" in analysis_options and 'fk_grade' in locals():

Â  Â  Â  Â  Â  Â  fk_grade = locals()['fk_grade']

Â  Â  Â  Â  Â  Â  flesch_ease = locals()['flesch_ease']

Â  Â  Â  Â  if "Language Detection" in analysis_options and 'detected_lang' in locals():

Â  Â  Â  Â  Â  Â  detected_lang = locals()['detected_lang']

Â  Â  Â  Â  if "Translation" in analysis_options and 'translation_result' in locals():

Â  Â  Â  Â  Â  Â  translation_result = locals()['translation_result']





Â  Â  Â  Â  all_results = {

Â  Â  Â  Â  Â  Â  "Original Text": input_text,

Â  Â  Â  Â  Â  Â  "Summary": summary,

Â  Â  Â  Â  Â  Â  "Keywords": ", ".join(keywords) if isinstance(keywords, list) else keywords,

Â  Â  Â  Â  Â  Â  "Sentiment": f"{label} (Confidence: {score:.2f})" if isinstance(score, float) else label,

Â  Â  Â  Â  Â  Â  "Entities": entity_data,

Â  Â  Â  Â  Â  Â  "Generated Text": generated_text,

Â  Â  Â  Â  Â  Â  "Topics": topics,

Â  Â  Â  Â  Â  Â  "Flesch-Kincaid Grade Level": fk_grade,

Â  Â  Â  Â  Â  Â  "Flesch Reading Ease Score": flesch_ease,

Â  Â  Â  Â  Â  Â  "Detected Language": detected_lang.upper() if isinstance(detected_lang, str) else detected_lang,

Â  Â  Â  Â  Â  Â  "Translated Text": translation_result,

Â  Â  Â  Â  }



Â  Â  Â  Â  # Format results for download

Â  Â  Â  Â  download_string = ""

Â  Â  Â  Â  for key, value in all_results.items():

Â  Â  Â  Â  Â  Â  download_string += f"--- {key} ---\n"

Â  Â  Â  Â  Â  Â  if isinstance(value, list):

Â  Â  Â  Â  Â  Â  Â  Â  for item in value:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if isinstance(item, dict):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  download_string += f"{item}\n"

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  download_string += f"{item}\n"

Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  download_string += f"{value}\n"

Â  Â  Â  Â  Â  Â  download_string += "\n"



Â  Â  Â  Â  st.download_button(

Â  Â  Â  Â  Â  Â  label="Download Analysis Results (TXT)",

Â  Â  Â  Â  Â  Â  data=download_string,

Â  Â  Â  Â  Â  Â  file_name="text_analysis_results.txt",

Â  Â  Â  Â  Â  Â  mime="text/plain"

Â  Â  Â  Â  )

Â  Â  else:

Â  Â  Â  Â  st.info("Enter text to enable result download.")



else:

Â  Â  st.info("Please enter some text above to start the analysis.")



st.markdown("---")

st.caption("Developed with Streamlit, Hugging Face Transformers, NLTK, spaCy, scikit-learn, textstat, langdetect, and wordcloud.")
